## <img src="/Images/Icons/peer_review.png" width="300" height="300" />

## 8. Otvorené recenzné konanie, metriky a hodnotenie

### Čo je to?

Byť výskumníkom znamená byť neustále hodnotený. V akademickom svete platí "ekonómia prestíže", čo znamená, že hodnota akademických pracovníkov sa odvíja od hodnotenia úrovne úcty?vážnosti?ocenenia LEVEL OF ESTEEM, ktoré im a ich príspevkom pripisujú kolegovia, tvorcovia politík (decision-makers) a iní ([Blackmore and Kandiko, 2011](https://doi.org/10/fqrkft)\). V tejto časti budeme preto rozlišovať medzi hodnotením diela a hodnotením samotných výskumníkov. Výskum aj výskumníci sa hodnotia pomocou dvoch základných metód: recenzného konania (kvalitatívna metóda) a metrík (kvantitatívna metóda). 

Recenzné konanie sa využíva predovšetkým na posúdenie vedeckého výskumu. Je to formálny mechanizmus zabezpečenia kvality, v rámci ktorého iní odborníci skúmajú vedecké rukopisy \(napr. články v časopisoch, knihy, žiadosti o granty a konferenčné príspevky\), ich spätná väzba a posudky potom slúžia na zlepšenie prác a konečný výber \(na publikovanie, pridelenie grantov alebo dĺžke času prezentácie príspevku\). Otvorené recenzné konanie znamená rôzne veci pre rôznych ľudí a komunity. Bolo definované ako "zastrešujúci výraz pre viacero prekrývajúcich sa spôsobov, ako možno modely recenzného konania zosúladiť s cieľmi otvorenej vedy" \([Ross-Hellauer, 2017](https://doi.org/10/gc5sjh)\). Dva hlavné znaky otvoreného recenzného konania sú "otvorené identity", kedy aj autori aj recenzenti navzájom poznajú svoju identitu \(t.j., nezaslepené recenzné konanie\), a "otvorené hodnotenia", kedy sú recenzie zverejnené spolu s príslušným článkom. Tieto znaky sa môžu ale nemusia kombinovať, môžu ich dopĺňať iné inovácie ako napríklad "otvorená participácia", kedy sa môžu členovia širšej komunity podieľať na recenznom konaní, "otvorené interakcie", kedy je umožnená a podporuje sa vzájomná diskusia medzi autorom/autormi a recenzentami a medzi recenzentami navzájom, a "otvorené rukopisy pred recenzovaním", kedy sú rukopisy dostupné ešte pred formálnym procesom recenzného konania \(buď interne ako súčasť pracovných postupov časopisu alebo externe cez preprintové servery\). 

Potom ako vedecké publikácie úspešne prejdú recenzným konaním, stávajú sa často hlavným meradlom práce vedca (preto fráza "publikuj alebo zhyň"). Ale posúdenie kvality publikácií je náročný a subjektívny proces. Hoci niektoré všeobecné systémy hodnotenia, napríklad Rámec excelentnosti výskumu v Spojenom kráľovstve (Research Excellence Framework), využívajú recenzné konanie, všeobecné hodnotenie je často založené na __metrikách__, ako je počet citácií publikácií (h-index) alebo dokonca aj vnímaná úroveň prestíže časopisu, v ktorom bol článok uverejnený (kvantifikovaná ako impakt faktor časopisu (JIF, Journal Impact Factor)). Na prevahu takýchto metrík a spôsob, akým môžu deformovať stimuly, v posledných rokoch často poukazovali vyhlásenia ako Leidenský manifest ([Leiden Manifesto](http://www.leidenmanifesto.org/)) a Sanfranciská deklarácia hodnotenia vedeckého výskumu ([San Francisco Declaration on Research Assessment (DORA)](https://sfdora.org/)), (pozn. prekl: v súčasnosti Dohoda o reforme hodnotenia výsledkov výskumu z roku 2022 (The Agreement on Reforming Research Assessment (https://www.scienceeurope.org/news/rra-agreement-final/)).

V posledných rokoch sa predmetom diskusie o vyváženom hodnotení výskumného úsilia stali "alternatívne metriky" alebo altmetriky ([altmetrics](https://www.altmetric.com)), ktoré dopĺňajú počítanie citácií meraním iných online ukazovateľov dopadu výskumu, vrátane knižných záložiek, odkazov, príspevkov na blogoch, tweetov, lajkov, zdieľaní, informácií v tlači a pod. Všetky tieto problémy s metrikami vyplývajú z toho, že ich tvoria komerčné subjekty (napr. Clarivate Analytics a Elsevier), ktoré sú založené na proprietárnych systémoch, čo môže viesť k problémom s transparentnosťou.   

## <img src="/Images/Icons/umbrella.png" width="150" height="150" />
### Odôvodnenie

#### Otvorené recenzné konanie
Počiatky recenzného konania siahajú do 17. storočia k londýnskej Kráľovskej spoločnosti (Royal Society of London, 1662) a parížskej Kráľovskej akadémii vied (Académie Royale des Sciences de Paris, 1699) v podobe privilégia vedy robiť si radšej vlastnú cenzúru, ako to nechať na cirkev, ale trvalo mnoho rokov, kým sa proces recenzného konania vo vede riadne etabloval. Recenzné konanie v podobe formálneho mechanizmu je oveľa mladší proces ako mnohí predpokladajú. Napríklad časopis Nature ho zaviedol až v roku 1967. Hoci prieskumy ukazujú, že výskumníci si cenia recenzné konanie, tiež si myslia, že by mohlo fungovať lepšie. Často sa vyskytujú sťažnosti na to, že recenzné konanie trvá príliš dlho, je nekonzistentné, často neodhalí chyby a že anonymita chráni nekorektné hodnotenie (bias). Otvorené recenzné konanie sa preto usiluje priniesť väčšiu transparentnosť a participáciu do formálneho a neformálneho procesu recenzného konania. Recenzovanie dáva vedcom príležitosť zapojiť sa do inovatívneho výskumu, vytvárať siete v akademickom prostredí, rozširovať svoje odborné znalosti a zdokonaľovať svoje vlastné zručnosti v oblasti písania. Je to dôležitý prvok kontroly kvality akademickej práce. A aj keď si samotní výskumníci myslia, že dobre poznajú tradičné recenzné konanie, mnoho foriem otvoreného recenzného konania predstavuje nové výzvy a príležitosti. Keďže otvorené recenzné konanie zahŕňa široké spektrum postupov, musia autori a recenzenti zobrať do úvahy mnoho faktorov. 

## <img src="/Images/02 Open Science Basics/02_open_peer_review.png" />

Pokiaľ ide o hodnotenie, súčasné odmeňovanie a metriky v oblasti vedy a vedeckého poznania nie sú \(zatiaľ\) v súlade s otvorenou vedou. Metriky používané na hodnotenie výskumu \(napr. impakt faktor časopisov/Journal Impact Factor, h-index\) nemerajú, a teda neodmeňujú, uplatňovanie postupov otvorenej vedy. Činnosť spojená s otvoreným recenzným konaním sa nie vždy uznáva ako "vedecká činnosť" v rámci odborného rastu a rozvoja \(napríklad v mnohých prípadoch hodnotitelia grantov nepovažujú ani prvotriedne otvorené recenzné posudky za samostatné vedecké práce\). Okrem toho nie sú mnohé hodnotiace metriky, obzvlášť niektoré druhy bibliometrík, také otvorené a transparentné, ako by komunita chcela.

Under those circumstances, at best Open Science practices are seen as an additional burden without rewards. At worst, they are seen as actively damaging chances of future funding and promotion as well as tenure. A recent [report from the European Commission (2017)](https://doi.org/10.2777/75255) recognizes that there are basically two approaches to Open Science implementation and the way rewards and evaluation can support that:

1. Simply support the status quo by encouraging more openness, building related metrics and quantifying outputs;

2. Experiment with alternative research practices and assessment, open data, citizen science and open education.

More and more funders and institutions are taking steps in these directions, for example by moving away from simple counts, and including narratives and indications of societal impact in their assessment exercises. Other steps funders are taking are allowing more types of research output \(such as preprints\) in applications and funding different types of research \(such as replication studies\).

## <img src="/Images/Icons/finish.png" width="150" height="150" />
### Ciele vzdelávania

1. Recognise the key elements of open peer review and their potential advantages and disadvantages
2. Understand the differences between types of metrics used to assess research and researchers
3. Engage with the debate over the way in which evaluation schema affect the ways in which scholarship is performed

### Kľúčové prvky
## <img src="/Images/Icons/brain.png" width="150" height="150" />
### Poznatky
#### Otvorené recenzné konanie

Popular venues for OPR include journals from publishers like Copernicus, Frontiers, BioMed Central, eLife and F1000research.

Open peer review, in its different forms, has many potential advantages for reviewers and authors:

* Open identities \(non-blinded\) review fosters greater accountability amongst reviewers and reduces the opportunities for bias or undisclosed conflicts of interest.

* Open review reports add another layer of quality assurance, allowing the wider community to scrutinize reviews to examine decision-making processes.

* In combination, open identities and open reports are theorized to lead to better reviews, as the thought of having their name publicly connected to a work or seeing their review published encourages reviewers to be more thorough.

* Open identities and open reports enable reviewers to gain public credit for their review work, thus incentivising this vital activity and allowing review work to be cited in other publications and in career development activities linked to promotion and tenure.

* Open participation could overcome problems associated with editorial selection of reviewers \(e.g., biases, closed-networks, elitism\). Especially for early career researchers who do not yet receive invitations to review, such open processes may also present a chance to build their research reputation and practice their review skills.

There are some potential pitfalls to watch out for, including:

* Open identities removes anonymity conditions for reviewers \(single-blind\) or authors and reviewers \(double-blind\) which are traditionally in place to counteract social biases \(although there is not strong-evidence that such anonymity has been effective\). It’s therefore important for reviewers to constantly question their assumptions to ensure their judgements reflect only the quality of the manuscript, and not the status, history, or affiliations of the author\(s\). Authors should do the same in receiving peer review comments.

* Giving and receiving criticism is often a process fraught with unavoidably emotional reactions - authors and reviewers may subjectively agree or disagree on how to present the results and/or what needs improvement, amendment or correction. In open identities and/or open reports, the transparency could exacerbate such difficulties. It is therefore essential that reviewers ensure that they communicate their points in a clear and civil way, in order to maximise the chances that it will be received as valuable feedback by the author\(s\).

* Lack of anonymity for reviewers in open identities review might subvert the process by discouraging reviewers from making strong criticisms, especially against higher-status colleagues.

* Finally, given these issues, potential reviewers may be more likely to decline to review.

#### Otvorené metriky

The [San Francisco Declaration on Research Assessment \(DORA\)](https://sfdora.org/) recommends moving away from journal based evaluations, consider all types of output and use various forms of metrics and narrative assessment in parallel. DORA has been signed by thousands of researchers, institutions, publishers and funders, who have now committed themselves to putting this in practice. The [Leiden Manifesto](http://www.leidenmanifesto.org/) provides guidance on how to use metrics responsibly.

Regarding Altmetrics, [Priem et al. (2010)](http://altmetrics.org/manifesto/) advise that altmetrics have the following benefits: they accumulate quicker than citations; they can gauge the impact of research outputs other than journal publications (e.g. datasets, code, protocols, blog posts, tweets, etc.); and they can provide diverse measures of impact for individual objects. The timeliness of altmetrics presents a particular advantage to early-career researchers, whose research-impact may not yet be reflected in significant numbers of citations, yet whose career-progression depends upon positive evaluations. In addition, altmetrics can help with early identification of influential research and potential connections between researchers. A recent report by the EC’s Expert Group on Altmetrics ([Wilsdon et al. (European Commission), 2017](https://ec.europa.eu/research/openscience/pdf/report.pdf)) identified challenges of altmetrics, including lack of robustness and susceptibility to ‘gaming’; that any measure ceases to be a good measure once it becomes a target (‘Goodhart’s Law’); relative lack of social media uptake in some disciplines and geographical regions; and a reliance on commercial entities for the underlying data.

## <img src="/Images/Icons/gears.png" width="150" height="150" />
### Zručnosti

Example exercises

* Trainees work in groups of three. Each individually writes a review of a short academic text

* Review a paper on a pre-print server

* Use a free bibliometrics or altmetrics service \(e.g. [Impactstory](https://impactstory.org/), [Paperbuzz](https://paperbuzz.org/), [Altmetric bookmarklet](https://www.altmetric.com/products/free-tools/bookmarklet/), [Dimensions.ai](https://www.dimensions.ai/)\) to look up metrics for a paper, then write a short explanation of how exactly various metrics reported by each service are calculated \(it’s harder than you’d assume; this would get at the challenges of finding proper metrics documentation for even the seemingly most transparent services\)

## <img src="/Images/Icons/questions.png" width="150" height="150" />
### Otázky, prekážky a bežné mylné predstavy
Q: Is research evaluation fair?

A: Research evaluation is as fair as its methods and evaluation techniques. Metrics and altmetrics try to measure research quality with research output quantity, which can be accurate, but does not have to be.


## <img src="/Images/Icons/output.png" width="150" height="150" />
### Výsledky vzdelávania

1. Trainees will be able to identify open peer review journals
2. Trainees will be aware of a range of metrics, their advantages and disadvantages

## <img src="/Images/Icons/magnifying_glass.png" width="150" height="150" />
### Ďalšie odporúčané čítanie

* Directorate-General for Research and Innovation (European Commission) (2017). Evaluation of Research Careers Fully Acknowledging Open Science Practices: Rewards, Incentives and/or Recognition for Researchers Practicing Open Science. [doi.org/10.2777/75255](https://doi.org/10.2777/75255)

* Hicks et al. (2015) Bibliometrics: The Leiden Manifesto for research metrics. [doi.org/10.1038/520429a](www.doi.org/10.1038/520429a), [leidenmanifesto.org](http://www.leidenmanifesto.org/)

* Peer Review the Nuts and Bolts (2012). A Guide for Early Career Researchers. [PDF](http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf)


### Projekty a iniciatívy 

* Make Data Count. [makedatacount.org](https://makedatacount.org/)

* NISO Alternative Assessment Metrics \(Altmetrics\) Initiative. [niso.org](http://www.niso.org/standards-committees/altmetrics)

* Open Rev. [openrev.org](https://en.wikipedia.org/wiki/Open_Rev)

* OpenUP Hub. [openuphub.eu](https://www.openuphub.eu/review)

* Peer Reviewers’ Openness Initiative. [opennessinitiative.org](https://opennessinitiative.org/)

* Peerage of Science. A free service for scientific peer review and publishing. [peerageofscience.org](https://www.peerageofscience.org/)

* Responsible Metrics. [responsiblemetrics.org](https://responsiblemetrics.org/)

* Snowball Metrics. Standardized research metrics - by the sector for the sector. [snowballmetrics.com](https://www.snowballmetrics.com/)
